{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nwandb.login(key=\"\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_config = {\n    'method':'grid'\n}\nparameters_dict = {\n    'fold':{\n        'values':[ 3,8, 9, 10, 11, 12, 13, 14, 15, 16]\n    }\n}\nsweep_config['parameters'] = parameters_dict\nparameters_dict.update({\n    'epochs':{\n      'value': 50\n    },\n    'batch_size':{\n        'value': 8\n    },\n    'learning_rate':{\n        'value': 3e-5\n    },\n    'weight_decay':{\n        'value': 9e-3\n    },\n    'loss':{\n        'value':'contrastive'\n    },\n    'optimizer':{\n        'value': 'AdamW'\n    },\n    'project_name':{\n        'value':\"siameseNet\"\n    },\n    'input_size':{\n        'value': (1,7*16000)\n    },\n    'sample_rate':{\n        'value': 16000\n    },\n    parameters_dict.update({\n    'sessionListDataset':{\n        'value':[9, 10, 11, 12, 13, 14, 15, 16]},\n    'dataset':{\n        'value':\"IEMOCAP_EMODB {}\".format(pair_path)\n    },\n    'source_dataset_path':{\n        'value':artifact_dir_iemocap\n    },\n    'target_dataset_path':{\n        'value':artifact_dir_emodb\n    },\n     'pair_dataset_path':{\n        'value':artifact_dir_pair\n    },\n    \n    'source_x_name':{\n         'value':'imocap'\n    },\n    'target_x_name':{\n        'value':'emodb'\n    },\n    'pair_name':{\n        'value':\"pairs.csv\"\n    },\n    'class_number':{\n        'value': 4\n    },\n    'class_names':{\n        'value':['neutral', 'happy', 'angry', 'sad']\n    },\n    'valid_labels':{\n        'value':['0', '1', '2', '3']\n    },\n#     'p':{\n#         'value': 1# in norm1 and norm2 is needed\n#     },\n    'distance':{\n        'value': 'contrastiveLoss-mmd'\n    },\n    'margin':{\n        'value':2\n    },\n    'sigma':{\n        'value':2\n    },\n   'kernel': {\n        'value':'rbf'\n    },\n    'freeze':{\n        'value':True\n    },\n    'initial_weights_library':{\n        'value':'distilhubert'\n    },\n\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# save_model = False\nsweep_id = input('What is sweep_id? (leave out if this is first sweep) ')\nif sweep_id==\"\":\n    sweep_id = wandb.sweep(sweep_config, project=parameters_dict['project_name']['value'])\nsaveModel = True\nsaveGradient = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_waveform(file_path, sample_rate=16000):\n      wf, sr = torchaudio.load(file_path)\n      resample = torchaudio.transforms.Resample(sr, sample_rate)\n      waveform = resample(wf)\n      return waveform\n    \ndef tile(waveform, expected_time):\n  waveform_time = waveform.shape[1]\n  expected_time = expected_time\n  repeat_times = (expected_time // waveform_time) + 1\n  tiled_data = waveform.repeat(1, repeat_times)  \n  return tiled_data[:, :expected_time]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_labels(labels):\n    emotion_label_dict={\n        'neutral':0,\n        'happy':1,\n        'angry':2,\n        'sad':3,\n    }\n    \n        \n    return [emotion_label_dict[emo] for emo in labels]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SiameseClassifierNetworkDataset(Dataset):\n    def __init__(self,csv_file_name,path_dataset1,path_dataset2,sessionList,x_name_source,x_name_target,\n                 sessionListName,class_label_name_contrastive):\n      #read csv file\n      df=pd.read_csv(csv_file_name)\n\n      self.path_dataset1=path_dataset1\n      self.path_dataset2=path_dataset2\n      #first and second columns of dataframe are the file names.\n      self.temp_df=df[df[sessionListName].isin( sessionList)].reset_index(drop=True)\n      self.speech1_path=self.temp_df[x_name_source].values\n      self.speech2_path=self.temp_df[x_name_target].values\n\n\n      self.label_contrastive=torch.tensor(self.temp_df[class_label_name_contrastive],dtype=torch.float)\n    \n        \n    def __getitem__(self,index):\n        speech1=tile(get_waveform(os.path.join(self.path_dataset1,self.speech1_path[index])),\n                     16000*7)\n        speech2=tile(get_waveform(os.path.join(self.path_dataset2,self.speech2_path[index])),\n                     16000*7)\n\n        return speech1,speech2,self.label_contrastive[index]#,self.label[index]\n    \n    def __len__(self):\n       \n        return self.temp_df.shape[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def initialization_weights(library,freezeList,freeze=False):\n    siamese_net=CnnNetwork().to(device)\n    if library =='distilhubert':\n        !pip install s3prl\n        from s3prl.hub import distilhubert\n        model = distilhubert().to(device)\n        state_dict=model.state_dict()\n        stateDict={}\n        stateDict['conv0.weight'] = state_dict['model.model.feature_extractor.conv_layers.0.0.weight']\n        stateDict['conv1.weight'] = state_dict['model.model.feature_extractor.conv_layers.1.0.weight']\n        stateDict['conv2.weight'] = state_dict['model.model.feature_extractor.conv_layers.2.0.weight']\n        stateDict['conv3.weight'] = state_dict['model.model.feature_extractor.conv_layers.3.0.weight']\n        stateDict['conv4.weight'] = state_dict['model.model.feature_extractor.conv_layers.4.0.weight']\n        stateDict['conv5.weight'] = state_dict['model.model.feature_extractor.conv_layers.5.0.weight']\n        stateDict['conv6.weight'] = state_dict['model.model.feature_extractor.conv_layers.6.0.weight']\n\n        stateDict['norm0.weight'] = state_dict['model.model.feature_extractor.conv_layers.0.2.weight']\n        stateDict['norm0.bias'] = state_dict['model.model.feature_extractor.conv_layers.0.2.bias']\n    \n        siamese_net.load_state_dict(stateDict,strict=False)\n        if freeze:\n            freezeTuple = tuple(freezeList)\n            for name,layer in siamese_net.named_parameters():\n                if name.startswith(freezeTuple):\n                    layer.requires_grad = False\n        \n    return siamese_net","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CnnNetwork(nn.Module):\n    def __init__(self):\n          super(CnnNetwork, self).__init__()\n          self.conv0 = nn.Conv1d(1 ,512 ,(10,) , stride = 5, bias=False)\n          #torch.transpose(x, 1, 2)\n          self.norm0 = nn.LayerNorm((512,))\n          #torch.transpose(x, 1, 2)\n          self.act0 = nn.GELU()\n          self.conv1 = nn.Conv1d(512, 512 , 3 ,stride = 2, bias=False )\n          self.norm1 = nn.LayerNorm((512,))\n          self.act1 = nn.GELU()\n          self.conv2 = nn.Conv1d(512, 512, 3 ,stride = 2, bias=False)\n          self.norm2 = nn.LayerNorm((512,))\n          self.act2 = nn.GELU()\n          self.conv3 = nn.Conv1d(512,512, 3, stride = 2, bias=False)\n          self.norm3 = nn.LayerNorm((512,))\n          self.act3 = nn.GELU()\n          self.conv4 = nn.Conv1d(512,512, 3, stride = 2, bias=False)\n          self.norm4 = nn.LayerNorm((512,))\n          self.act4 = nn.GELU()\n          self.conv5 = nn.Conv1d(512,512, 2, stride = 2, bias=False)\n          self.norm5 = nn.LayerNorm((512,))\n          self.act5 = nn.GELU()\n          self.conv6 = nn.Conv1d(512,512, 2, stride = 2, bias=False)\n          self.norm6 = nn.LayerNorm((512,))\n          self.act6 = nn.GELU()\n          #self.pool4 = nn.MaxPool2d(1, stride = 2)\n          #self.conv5 = nn.Conv2d(512,7, (1,1), stride = 1)\n    def forward(self, x):\n        \n        out = self.conv0(x)\n        #print(out.shape)\n        out = torch.transpose(out, 1, 2)\n        out = self.norm0(out)\n        out = torch.transpose(out, 1, 2)\n        out = self.act0(out)\n        out = self.conv1(out)\n        #print(out.shape)\n        out = torch.transpose(out, 1, 2)\n        out = self.norm1(out)\n        out = torch.transpose(out, 1, 2)\n        out = self.act1(out)\n        #print(out.shape)\n        out = self.conv2(out)\n        #print(out.shape)\n        out = torch.transpose(out, 1, 2)\n        out = self.norm2(out)\n        out = torch.transpose(out, 1, 2)\n        out = self.act2(out)\n        #print(out.shape)\n        out = self.conv3(out)\n        #print(out.shape)\n        out = torch.transpose(out, 1, 2)\n        out = self.norm3(out)\n        out = torch.transpose(out, 1, 2)\n        out = self.act3(out)\n        #print(out.shape)\n        #out = self.norm4(out)\n        #print(out.shape)\n        #out = self.silu4(out)\n        #print(out.shape)\n        #out = self.pool4(out)\n        out = self.conv4(out)\n        #print(out.shape)\n        out = torch.transpose(out, 1, 2)\n        out = self.norm4(out)\n        out = torch.transpose(out, 1, 2)\n        out = self.act4(out)\n        out = self.conv5(out)\n        #print(out.shape)\n        out = torch.transpose(out, 1, 2)\n        out = self.norm5(out)\n        out = torch.transpose(out, 1, 2)\n        out = self.act5(out)\n        out = self.conv6(out)\n        #print(out.shape)\n        out = torch.transpose(out, 1, 2)\n        out = self.norm6(out)\n        out = torch.transpose(out, 1, 2)\n        out = self.act6(out)\n#         print(\"out shape\",out.shape)\n        return out\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#create the Siamese Neural Network\nclass SiameseNetwork(nn.Module):\n\n    def __init__(self,model,layers):\n      super(SiameseNetwork, self).__init__()\n      self.model = model\n      self.layersLst = []\n      self.layersTuple = tuple(layers)\n      for name, layer in self.model.named_modules():\n            layer.register_forward_hook(self._save_layer_output(name))\n\n    def _save_layer_output(self,name):\n            def hook(module,input,output):\n                if isinstance(module,nn.Conv1d) and name.startswith(self.layersTuple):\n                    print(\"in nn.Conv1d \", output.size())\n                    self.layersLst.append(output)\n                elif isinstance(module,nn.LayerNorm) and name.startswith(self.layersTuple):\n                    print(\"in nn.LayerNorm size \", output.size())\n                    self.layersLst.append(rearrange(output, \"t b c ->b c t\"))\n            return hook  \n    def forward_once(self, x):\n        # This function will be called for both images\n        # It's output is used to determine the similiarity\n        self.layersLst=[]\n        _ = self.model(x)\n        return self.layersLst\n\n    def forward(self, input1, input2):\n        # In this function we pass in both images and obtain both vectors\n        # which are returned\n\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n\n        return output1, output2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MMD_loss(nn.Module):\n    def __init__(self,config):\n        super(MMD_loss,self).__init__()\n        self.config=config\n        self.kernel=config.kernel\n    def gaussian_kernel(self,a, b):\n        dim1_1, dim1_2 = a.shape[0], b.shape[0]\n        depth = a.shape[1]\n        sigma=self.config.sigma\n        a = a.view(dim1_1, 1, depth)\n        b = b.view(1, dim1_2, depth)\n\n        a_core = a.expand(dim1_1, dim1_2, depth)\n        b_core = b.expand(dim1_1, dim1_2, depth)\n        numerator = (a_core - b_core).pow(2).mean(2)/(2.0 * sigma ** 2)\n        c=torch.exp(-numerator)\n#         print(\"torch.exp(-numerator) size\",c.size())\n        return c\n\n    def polynomial_kernel(self,X, Y, c, p):\n        \"\"\"\n        Compute the polynomial kernel between two matrices X and Y::\n            K(x, y) = (<x, y> + c)^p\n        \"\"\"\n        return ((X @ Y.transpose(0,1) + c) ** p)\n\n    def forward(self,a, b):\n        functionDict={\n            'rbf':lambda a,b :self.gaussian_kernel(a,b),\n            'polynomial':lambda a,b:self.polynomial_kernel(a,b,1,2)\n        }\n        \n        XX=functionDict[self.kernel](a,a)\n        YY=functionDict[self.kernel](b,b)\n        XY=functionDict[self.kernel](a,b)\n#         print(\"XX\",XX.size())\n#         print(\"YY\",YY.size())\n#         print(\"XY\",XY.size())\n        print(\"torch.mean(XX + YY - 2*XY,1)\",torch.mean(XX + YY - 2*XY,1))\n        return torch.mean(XX + YY - 2*XY,1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ContrastiveLoss(nn.Module):\n    def __init__(self,config):\n        super(ContrastiveLoss,self).__init__()\n        self.config = config\n    def forward(self,output1, output2,label=None):\n        result_distance = 0\n        if 'norm' in self.config.distance :\n            distanceObj = nn.PairwiseDistance(p = self.config.p).to(device)\n        elif self.config.distance.endswith('mmd'):\n            distanceObj = MMD_loss(self.config).to(device)\n        elif self.config.distance =='cosine':\n            distanceObj = nn.CosineSimilarity(dim=1, eps=1e-6).to(device)\n        for i,(x,y) in enumerate(zip(output1,output2)):\n            distance = distanceObj(torch.mean(x,dim=2),torch.mean(y,dim=2))\n            print(\"distance before if \",distance)\n            if self.config.distance.startswith('contrastiveLoss') and label!=None:\n                #0 same emotion 1 different emotion\n                distance = torch.mean((1-label) * torch.pow(distance, 2) +\n                                    (label) * torch.pow(torch.clamp(self.config.margin - distance, min=0.0), 2))\n                \n                result_distance = result_distance+distance\n\n        return result_distance","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make(config):\n    model = initialization_weights(config.initial_weights_library,config.freezeList,freeze=config.freeze)\n    siamese_net = SiameseNetwork(model,config.distanceList)\n#     if config.freeze:\n#         for param in siamese_net.parameters():\n#             param.requires_grad = False\n#     contrastive = ContrastiveLayers(config)\n#     net = Classifier(siamese_net,contrastive,config)\n    net = siamese_net\n    if torch.cuda.device_count()>1:\n        net = nn.DataParallel(siamese_net,device_ids=[0, 1])\n        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n    net.to(device)\n    criterion = ContrastiveLoss(config)#nn.BCELoss()#nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.AdamW(net.parameters(),\n                                  lr = config.learning_rate,\n                                  weight_decay = config.weight_decay)\n    return net,criterion,optimizer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_train_loader(config):\n    classifier_dataset = SiameseClassifierNetworkDataset(csv_file_name=os.path.join(config.pair_dataset_path,config.pair_name),\n                                        path_dataset1=config.source_dataset_path,\n                                        path_dataset2=config.target_dataset_path,\n                                       sessionList=[i for i in config.sessionListDataset if i!=config.fold],\n                                       x_name_source=config.source_x_name,\n                                       x_name_target=config.target_x_name,\n                                       sessionListName='emodb_session' ,\n                                      class_label_name_contrastive='pos_neg')\n    train_dataloader = DataLoader(classifier_dataset, batch_size=config.batch_size, num_workers=2, shuffle=True)\n    return train_dataloader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"PATH='model.pkl'\ndef train(config,net,criterion,optimizer):\n\n    train_dataloader= make_train_loader(config)\n    wandb.watch(net, criterion, log=\"all\", log_freq=1,log_graph=True)\n    net.train()\n    # Iterate throught the epochs\n    for epoch in range(config.epochs):\n        train_loss = []\n        # Iterate over batches\n        for i, (speech0, speech1,contrastive_label) in enumerate(train_dataloader):\n            \n            # Send the speech and labels to CUDA\n            speech0,speech1,contrastive_label = speech0.squeeze(1).to(device),speech1.squeeze(1).to(device), contrastive_label.to(device)\n\n            # Zero the gradients (PyTorch accumulates the gradients on subsequent backward passes. \n            #This accumulating behaviour is convenient while training RNNs or when we want to compute the gradient of the loss summed over multiple mini-batches.)\n            optimizer.zero_grad()\n\n\n\n#             with autocast():\n            # Pass in the two speeches into the network and obtain two outputs and classifier output for the  source speech\n#             if config.distance.startswith( 'contrastiveLoss'):\n# #                 print(\"speech0\",speech0.dtype)\n# #                 print(\"contrastive_label in contrastiveLoss\",contrastive_label)\n#                 a = net(speech0, speech1,contrastive_label)\n#             else:\n\n            x1,x2 = net(speech0, speech1)\n\n            loss = criterion(x1,x2, contrastive_label)\n            # Calculate the backpropagation\n            loss.backward()\n            # Optimize\n            train_loss.append(loss.item())\n        wandb.log({\n            \"Train loss\": np.mean(train_loss),  \n          step=epoch+1)\n            \n\n        torch.save(net.state_dict(), PATH)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_model(config):\n        pickle_artifact = wandb.Artifact(\n            name = f'model.pkl',\n            type=\"model\",\n            metadata=dict(config))\n        wandb.save(PATH)\n\n        pickle_artifact.add_file(PATH)\n\n\n        wandb.log_artifact(pickle_artifact)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_model_pipeline(hyperparameters=None):\n    with wandb.init(config=hyperparameters):\n        # access all HPs through wandb.config, so logging matches execution!\n        config = wandb.config\n        net,criterion,optimizer=make(config) \n        # train model\n        train(config,net,criterion,optimizer)\n        if saveModel:\n            save_model(config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Build, train and analyze the model with the pipeline\n\nwandb.agent(sweep_id,project=parameters_dict['project_name']['value'],entity='',function=make_model_pipeline)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}